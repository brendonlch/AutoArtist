{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"AutoArtist_Autoencoder.ipynb","provenance":[],"collapsed_sections":["0shx-xwxxdZe","Xbixd2x8qSSs","9yxeWp7QqYl0","lpzbjA-_xwIG","1R3Wb0_Xx1at","jbn2uDPYx36V","NcaYClLjrU81","6-p2vKrOrwON","d6sQBHnAogaj","qqIaC8ZqonUs","_x05QOOS4Wws"],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyPosd1CJ50bZWRKHit/atOq"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0shx-xwxxdZe"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"B8uRQBUv541Y"},"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import keras\n","import tensorflow as tf\n","import zipfile\n","import requests\n","\n","# For Image Processing\n","import matplotlib.pyplot as plt\n","import glob\n","from PIL import Image \n","from matplotlib.image import imread\n","\n","# For Model Building\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.layers import Dense,Flatten,Reshape,Conv2D,MaxPooling2D,Input,UpSampling2D,Lambda,BatchNormalization,Dropout,Conv2DTranspose\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.optimizers import SGD,Adam\n","from skimage.measure import compare_ssim as ssim\n","from keras import backend as K\n","from sklearn.model_selection import train_test_split\n","\n","# For DeOldify\n","import io\n","import base64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJNQ58Ky6YWc"},"source":["# Check if GPU is active and the GPU's model\n","# !nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xbixd2x8qSSs"},"source":["## Load and process images"]},{"cell_type":"code","metadata":{"id":"80yQW-Yh6Z0I"},"source":["# Mount your google drive where the zipped images files are located\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AC16We-J6bZM"},"source":["# Ensuring that all zipped files are available\n","import os\n","for dirname, _, filenames in os.walk('/content/drive/My Drive/ML_Project/cracks'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISRPzMXA6sxt"},"source":["# path to zipped & working directories\n","path_zip = '/content/drive/My Drive/ML_Project/cracks/'\n","path = '/content/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlDrFOzn6tyG"},"source":["# Unzipping all necessary files\n","!unzip '/content/drive/My Drive/ML_Project/cracks/train7.zip'\n","!unzip '/content/drive/My Drive/ML_Project/cracks/label7.zip'\n","\n","!unzip '/content/drive/My Drive/ML_Project/cracks/train8.zip'\n","!unzip '/content/drive/My Drive/ML_Project/cracks/label8.zip'\n","\n","!unzip '/content/drive/My Drive/ML_Project/cracks/train9.zip'\n","!unzip '/content/drive/My Drive/ML_Project/cracks/label9.zip'\n","\n","!unzip '/content/drive/My Drive/ML_Project/cracks/train10.zip'\n","!unzip '/content/drive/My Drive/ML_Project/cracks/label10.zip'\n","\n","print(\"Unzipping completed\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fqrrV48n7nBb"},"source":["# Convert training images into numpy array values\n","train_path7 = \"/content/train7/*\"\n","train_path8 = \"/content/train8/*\"\n","train_path9 = \"/content/train9/*\"\n","train_path10 = \"/content/train10/*\"\n","\n","train_images = []\n","\n","\n","for f in sorted(glob.iglob(train_path7))[:2500]:\n","    train_images.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(train_path8))[:2500]:\n","    train_images.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(train_path9))[:2500]:\n","    train_images.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(train_path10))[:2500]:\n","    train_images.append(np.asarray(Image.open(f)) )\n","\n","train_images = np.array(train_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHif0E3p8bS_"},"source":["# Convert label images into numpy array values\n","label_path7 = \"/content/label7/*\"\n","label_path8 = \"/content/label8/*\"\n","label_path9 = \"/content/label9/*\"\n","label_path10 = \"/content/label10/*\"\n","\n","train_labels = []\n","\n","for f in sorted(glob.iglob(label_path7))[:2500]:\n","    train_labels.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(label_path8))[:2500]:\n","    train_labels.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(label_path9))[:2500]:\n","    train_labels.append(np.asarray(Image.open(f)) )\n","\n","for f in sorted(glob.iglob(label_path10))[:2500]:\n","    train_labels.append(np.asarray(Image.open(f)) )\n","\n","train_labels = np.array(train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9yxeWp7QqYl0"},"source":["## Train Test Split"]},{"cell_type":"code","metadata":{"id":"yyo--cfS9Opw"},"source":["x_train, x_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.25, random_state=42, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lpzbjA-_xwIG"},"source":["## Custom botCallback"]},{"cell_type":"code","metadata":{"id":"IuV4H9wo9fly"},"source":["# Input Personal Access Token for botCallback to be active\n","\n","# access_token = \n","\n","class botCallback(tf.keras.callbacks.Callback):\n","    def __init__(self,access_token):\n","        self.access_token = access_token\n","        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/getUpdates'\n","        self.response = requests.get(self.ping_url).json()\n","        self.chat_id = 161225240\n","\n","\n","    def send_message(self,message):\n","        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/sendMessage?'+\\\n","                        'chat_id='+str(self.chat_id)+\\\n","                        '&parse_mode=Markdown'+\\\n","                        '&text='+message\n","        self.response = requests.get(self.ping_url)\n","\n","    def send_model(self, filepath):\n","            chat_id = 161225240\n","            bot_api = '1389473435:AAFFxnOdJe83bqfDI15EZ_rjrTQiDfKtkcI'\n","            file = {'document': open(filepath, 'rb')}\n","            teleurl = f\"https://api.telegram.org/bot{bot_api}/sendDocument?chat_id={chat_id}\"\n","            requests.post(teleurl, files = file)\n","        \n","    def send_photo(self,filepath):\n","        file_ = open(filepath,'rb')\n","        file_dict = {'photo':file_}\n","        self.ping_url = 'https://api.telegram.org/bot'+str(self.access_token)+'/sendPhoto?'+\\\n","                    'chat_id='+str(self.chat_id)\n","        self.response = requests.post(self.ping_url,files = file_dict)\n","        file_.close()\n","\n","    def on_train_batch_begin(self, batch, logs=None):\n","        pass\n","    \n","    def on_train_batch_end(self, batch, logs=None):\n","#         message = ' Iteration/Batch {}\\n Training Accuracy : {:7.2f}\\n Training Loss : {:7.2f}\\n'.format(batch,logs['accuracy'],logs['mae'])\n","#         self.send_message(message)\n","        pass\n","\n","    def on_test_batch_begin(self, batch, logs=None):\n","        pass\n","    \n","    def on_test_batch_end(self, batch, logs=None):\n","#         message = ' Iteration/Batch {}\\n Training Accuracy : {:7.2f}\\n Training Loss : {:7.2f}\\n'.format(batch,logs['accuracy'],logs['mae'])\n","#         self.send_message(message)\n","        pass\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        pass\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch%10==0:\n","            filepath = f'mse_{epoch}.h5'\n","            self.model.save(filepath)\n","            self.send_model(filepath)\n","            Y_test = self.model.predict(x_test, batch_size=16)\n","            plt.figure(figsize=(15,25))\n","            for i in range(0,8,2):\n","                plt.subplot(4,2,i+1)\n","                plt.xticks([])\n","                plt.yticks([])\n","                plt.imshow(x_test[i*2][:,:,0], cmap='gray')\n","                plt.title('Noisy image MSE')\n","\n","                plt.subplot(4,2,i+2)\n","                plt.xticks([])\n","                plt.yticks([])\n","                plt.imshow(Y_test[i*2][:,:,0], cmap='gray')\n","                plt.title('Denoised by autoencoder MSE')\n","\n","            plt.savefig('hi.png')\n","            self.send_photo('./hi.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Az82mE009gkf"},"source":["# Uncomment and run this only if access_token variable is input from previous line\n","# bot_callback = botCallback(access_token)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1R3Wb0_Xx1at"},"source":["## Custom metrics"]},{"cell_type":"code","metadata":{"id":"47BuDhgWGXcM"},"source":["# Custom Metrics\n","def ssim_loss(y_true,y_pred):\n","    return tf.image.ssim(y_true,y_pred,max_val=255)\n","\n","def PSNR(y_true,y_pred):\n","    return tf.image.psnr(y_true,y_pred,max_val=255)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jbn2uDPYx36V"},"source":["## Model architecture"]},{"cell_type":"code","metadata":{"id":"P98WVei79iVq"},"source":["input_layer = Input(shape=(250,400,2))\n","\n","# Encoding\n","encoder = Sequential()\n","encoder.add(input_layer)\n","encoder.add(Conv2D(16,(5,5),activation='relu',padding='same'))\n","encoder.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n","encoder.add(Conv2D(64,(5,5),activation='relu',padding='same'))\n","\n","encoder.add(Conv2D(128,(5,5),activation='relu',padding='same'))\n","\n","encoder.add(BatchNormalization())\n","encoder.add(MaxPooling2D((5,5),padding='same'))\n","\n","encoder.add(Dropout(0.5))\n","\n","# Decoding\n","decoder = Sequential()\n","\n","decoder.add(Conv2D(128,(5,5),input_shape=[50,80,128],activation='relu',padding='same'))\n","decoder.add(Conv2D(64,(5,5),activation='relu',padding='same'))\n","decoder.add(Conv2D(32,(5,5),activation='relu',padding='same'))\n","decoder.add(Conv2D(16,(5,5),activation='relu',padding='same'))\n","encoder.add(BatchNormalization())\n","decoder.add(UpSampling2D((5,5)))\n","\n","decoder.add(Conv2D(2,(5,5),activation='relu',padding='same'))\n","\n","# Merge both Encoding and Decoding models into 1\n","noise_remover = Sequential([encoder,decoder])\n","\n","\n","# ALL CALLBACKS\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n","                                            patience=10, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.000000003)\n","\n","# Compiling Model\n","noise_remover.compile(loss='mean_squared_error',\n","                    optimizer=Adam(lr=0.000003),\n","                    metrics=[PSNR,ssim_loss,'mae'])\n","\n","\n","# Uncomment the codes below to train and save a new Autoencoder model\n","\n","# Fit Model\n","# noise_remover.fit(x_train,y_train,epochs=500,validation_data=(x_test,y_test),\n","#                 batch_size=16,verbose=1,callbacks=[learning_rate_reduction,bot_callback])\n","\n","# Saving the model\n","# noise_remover.save('/content/drive/My Drive/final_mse_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvx7BWMm9mGf","colab":{"background_save":true}},"source":["# Uncomment and run this only if access_token variable is input from previous line\n","\n","# def send_message(message):\n","#     chat_id = 161225240\n","#     bot_api = '1389473435:AAFFxnOdJe83bqfDI15EZ_rjrTQiDfKtkcI'\n","#     teleurl = f\"https://api.telegram.org/bot{bot_api}/sendMessage?chat_id={chat_id}&text={message}\"\n","#     print('Message Sent!')\n","#     requests.get(teleurl)\n","# send_message('Finished MSE Model Training!')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NcaYClLjrU81"},"source":["## Model's metric evaluation"]},{"cell_type":"code","metadata":{"id":"xUSKajZh9nvB","colab":{"background_save":true}},"source":["metrics = pd.DataFrame(noise_remover.history.history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzMoF2d79o0S","colab":{"background_save":true}},"source":["metrics[['mae','val_mae']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9jD8clyN9qk5","colab":{"background_save":true}},"source":["metrics[['loss','val_loss']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5wdpzUN_tUBT","colab":{"background_save":true}},"source":["metrics[['PSNR','val_PSNR']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fXZjoGstV8e","colab":{"background_save":true}},"source":["metrics[['ssim_loss','val_ssim_loss']].plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zwPa1hmyFFs"},"source":["metrics.tail(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6-p2vKrOrwON"},"source":["## Model's visual evaluation"]},{"cell_type":"code","metadata":{"id":"28FZRdM-9wpa","colab":{"background_save":true}},"source":["# Print Noisey Images vs. Denoised Images for Visual Evaluation\n","noisey_images = x_test[:150:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egc7S0e89xcO","colab":{"background_save":true}},"source":["noisey_images.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nL30zTBu9yZz","colab":{"background_save":true}},"source":["denoised = noise_remover(noisey_images)\n","denoised.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OABcPcv69zMe","colab":{"background_save":true}},"source":["for i in range(0,30):\n","    plt.imshow(noisey_images[i][:,:,0],cmap='gray')\n","    plt.show()\n","    plt.imshow(denoised[i][:,:,0],cmap='gray')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ri50vtAVoQk0"},"source":["## Load model weights for testing\n","\n","\n","For test purposes, run the following:\n","\n","1.   Import libraries\n","2.   Custom metrics\n","3.   Model architecture\n","\n","**After running the above 3 codes, ensure the filepaths for .h5 file and test images are in the correct directory before proceeding. You may change the directory path if needed.**\n","\n","Proceed with running the bottom codes linearly to evaluate test images, before and after denoising + colourization by DeOldify."]},{"cell_type":"code","metadata":{"id":"DRCC_bpG-FQs"},"source":["noise_remover.built = True\n","noise_remover.load_weights('/content/final_mse_weights.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pHWux0RIr46D"},"source":["# View model summary\n","noise_remover.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6sQBHnAogaj"},"source":["## Load test image"]},{"cell_type":"code","metadata":{"id":"XR6wJE8-90tn"},"source":["# Insert the directory of test image in img_path variable\n","img_path = '/content/test_img2.png'\n","test_image = Image.open(img_path).convert('LA')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yuMJ7lan91lw"},"source":["new_size = (400,250)\n","test_image = test_image.resize(new_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yqypgWJ792XT"},"source":["test_image = np.asarray(test_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X6SYGuho93FP"},"source":["# test_image.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGbTaBzB93tQ"},"source":["# View Test Image\n","plt.imshow(test_image[:,:,0], cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qqIaC8ZqonUs"},"source":["## Use model to denoise test image"]},{"cell_type":"code","metadata":{"id":"CLIyj4-iteoQ"},"source":["test_image = test_image.reshape(1,250,400,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnZaBDs796e5"},"source":["one_test = noise_remover.predict(test_image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nLmWIdPMfyig"},"source":["# one_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i3DsYGydgLjc"},"source":["one_test = one_test.reshape(250,400,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"liCsxjrpsCoi"},"source":["# View Denoised Test Image for comparison\n","plt.imshow(one_test[:,:,0], cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_x05QOOS4Wws"},"source":["## Calling of DeOldify via api to colourize restored photographs for final evaluation"]},{"cell_type":"code","metadata":{"id":"m0SLY9Sa51h3"},"source":["b, d = io.BytesIO(), io.BytesIO()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z4DRkCbc4WAF"},"source":["result = one_test.astype('uint8')\n","result = Image.fromarray(result[:,:,0])\n","result.save(b, 'PNG')\n","\n","r = requests.post(\n","    \"https://api.deepai.org/api/colorizer\",\n","    files={\n","        'image': base64.encodebytes(b.getvalue()).decode('ascii'),\n","    },\n","    headers={'api-key': '99173fcd-6b66-4592-a182-d23ff23b0787'} # replace this with your api keys!\n",")\n","url = r.json()['output_url']\n","response = requests.get(url)\n","img = Image.open(io.BytesIO(response.content))\n","# Save denoised test image\n","img.save('/content/denoised_test_img.png')\n","# Visual evaluation of denoised test image with colour on notebook\n","img"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeXMlFTe5Qwb"},"source":[""],"execution_count":null,"outputs":[]}]}